{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c2056a",
   "metadata": {},
   "source": [
    "# End-to-End Diabetes Machine Learning Pipeline II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8db9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions \n",
    "#utils.py \n",
    "#helpers.py -> dışarıdan çağırılabilir bunlar fonksiyonları bir arada görmemizi sağlar   \n",
    "# config.py -> dışarıdan ayarlanabilir şeyleri bu dosya içerisine de koyabiliriz. \n",
    "# from ile çağırabilir ve kullanabilir  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f10e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb61ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/tolga/OneDrive/Masaüstü/ML_YAZ_KAMPI/Machine Learning/datasets/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05294a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab_col_names \n",
    "\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "    Veri setindeki kategorik, numerik ve kategorik fakat kardinal değişkenlerin isimlerini verir.\n",
    "    Not: Kategorik değişkenlerin içerisine numerik görünümlü kategorik değişkenler de dahildir.\n",
    "    Parameters\n",
    "    ------\n",
    "        dataframe: dataframe\n",
    "                Değişken isimleri alınmak istenilen dataframe\n",
    "        cat_th: int, optional\n",
    "                numerik fakat kategorik olan değişkenler için sınıf eşik değeri\n",
    "        car_th: int, optinal\n",
    "                kategorik fakat kardinal değişkenler için sınıf eşik değeri\n",
    "    Returns\n",
    "    ------\n",
    "        cat_cols: list\n",
    "                Kategorik değişken listesi\n",
    "        num_cols: list\n",
    "                Numerik değişken listesi\n",
    "        cat_but_car: list\n",
    "                Kategorik görünümlü kardinal değişken listesi\n",
    "    Examples\n",
    "    ------\n",
    "        import seaborn as sns\n",
    "        df = sns.load_dataset(\"iris\")\n",
    "        print(grab_col_names(df))\n",
    "    Notes\n",
    "    ------\n",
    "        cat_cols + num_cols + cat_but_car = toplam değişken sayısı\n",
    "        num_but_cat cat_cols'un içerisinde.\n",
    "        Return olan 3 liste toplamı toplam değişken sayısına eşittir: cat_cols + num_cols + cat_but_car = değişken sayısı\n",
    "    \"\"\"\n",
    "\n",
    "    # cat_cols, cat_but_car\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # num_cols\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    print(f\"Observations: {dataframe.shape[0]}\")\n",
    "    print(f\"Variables: {dataframe.shape[1]}\")\n",
    "    print(f'cat_cols: {len(cat_cols)}')\n",
    "    print(f'num_cols: {len(num_cols)}')\n",
    "    print(f'cat_but_car: {len(cat_but_car)}')\n",
    "    print(f'num_but_cat: {len(num_but_cat)}')\n",
    "    return cat_cols, num_cols, cat_but_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a87d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#görevi : kendisine gelen değişkenleri alt ve üst sınır tanımlar \n",
    "# ön tanımlı değerleri : q1: 0.25 , q3: 0.75\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f6e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aykırı değeri gönder yerine bunu koy dersek kullanırız\n",
    "\n",
    "def replace_with_thresholds(dataframe, variable):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf114e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yeni türettiğimiz değişkenlerde kategorik değişkenleri ortaya çıkarmak için \n",
    "# dummy değişken tuzağından kurtulmak istiyoruz \n",
    "\n",
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5efe9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hepsini tek bir fonksiyon içerisinde de yazabiliriz. \n",
    "\n",
    "def diabetes_data_prep(dataframe):\n",
    "    dataframe.columns = [col.upper() for col in dataframe.columns]\n",
    "\n",
    "    # Glucose\n",
    "    dataframe['NEW_GLUCOSE_CAT'] = pd.cut(x=dataframe['GLUCOSE'], bins=[-1, 139, 200], labels=[\"normal\", \"prediabetes\"])\n",
    "\n",
    "    # Age\n",
    "    dataframe.loc[(dataframe['AGE'] < 35), \"NEW_AGE_CAT\"] = 'young'\n",
    "    dataframe.loc[(dataframe['AGE'] >= 35) & (dataframe['AGE'] <= 55), \"NEW_AGE_CAT\"] = 'middleage'\n",
    "    dataframe.loc[(dataframe['AGE'] > 55), \"NEW_AGE_CAT\"] = 'old'\n",
    "\n",
    "    # BMI\n",
    "    dataframe['NEW_BMI_RANGE'] = pd.cut(x=dataframe['BMI'], bins=[-1, 18.5, 24.9, 29.9, 100],\n",
    "                                        labels=[\"underweight\", \"healty\", \"overweight\", \"obese\"])\n",
    "\n",
    "    # BloodPressure\n",
    "    dataframe['NEW_BLOODPRESSURE'] = pd.cut(x=dataframe['BLOODPRESSURE'], bins=[-1, 79, 89, 123],\n",
    "                                            labels=[\"normal\", \"hs1\", \"hs2\"])\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    df = one_hot_encoder(dataframe, cat_cols, drop_first=True)\n",
    "\n",
    "    df.columns = [col.upper() for col in df.columns]\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(df, cat_th=5, car_th=20)\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if \"OUTCOME\" not in col]\n",
    "\n",
    "    replace_with_thresholds(df, \"INSULIN\")\n",
    "\n",
    "    X_scaled = StandardScaler().fit_transform(df[num_cols])\n",
    "    df[num_cols] = pd.DataFrame(X_scaled, columns=df[num_cols].columns)\n",
    "\n",
    "    y = df[\"OUTCOME\"]\n",
    "    X = df.drop([\"OUTCOME\"], axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69fee92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_models(X,y, scoring = \"roc_auc\"): \n",
    "    print(\"Base Models.....\") \n",
    "    classifiers = [('LR',LogisticRegression()), \n",
    "                  ('KNN',KNeighborsClassifier()), \n",
    "                  (\"SVC\",SVC()), \n",
    "                  (\"CART\",DecisionTreeClassifier()), \n",
    "                  (\"RF\",RandomForestClassifier()),\n",
    "                  ('Adaboost',AdaBoostClassifier()), \n",
    "                  ('GBM',GradientBoostingClassifier()), \n",
    "                  ('XGBoost',XGBClassifier(use_label_encoder=False,eval_metric='logloss')), \n",
    "                  ('LightGBM', LGBMClassifier()), \n",
    "                  #('CatBoost', CatBoostClassifier(verbose= False)) \n",
    "                  ] \n",
    "    \n",
    "    for name, classifier in classifiers:\n",
    "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
    "        print(f\"{scoring}: {round(cv_results['test_score'].mean(), 4)} ({name}) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fcdb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\"n_neighbors\": range(2, 50)}\n",
    "\n",
    "cart_params = {'max_depth': range(1, 20),\n",
    "               \"min_samples_split\": range(2, 30)}\n",
    "\n",
    "rf_params = {\"max_depth\": [8, 15, None],\n",
    "             \"max_features\": [5, 7, \"auto\"],\n",
    "             \"min_samples_split\": [15, 20],\n",
    "             \"n_estimators\": [200, 300]}\n",
    "\n",
    "xgboost_params = {\"learning_rate\": [0.1, 0.01],\n",
    "                  \"max_depth\": [5, 8],\n",
    "                  \"n_estimators\": [100, 200]}\n",
    "\n",
    "lightgbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "                   \"n_estimators\": [300, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a98710",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('KNN', KNeighborsClassifier(), knn_params),\n",
    "               (\"CART\", DecisionTreeClassifier(), cart_params),\n",
    "               (\"RF\", RandomForestClassifier(), rf_params),\n",
    "               ('XGBoost', XGBClassifier(use_label_encoder=False, eval_metric='logloss'), xgboost_params),\n",
    "               ('LightGBM', LGBMClassifier(), lightgbm_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b597056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(X,y, cv=3, scoring= \"roc_auc\"): \n",
    "    print(\"Hyperparameter Optimization...\") \n",
    "    best_models = {} \n",
    "    for name,classifier,params in classifiers: \n",
    "        print(f\"#######  {name} ########\")  \n",
    "        cv_results = cross_validate(classifier, X,y, cv=cv, scoring=scoring) \n",
    "        print(f\"{scoring} (Before):{round(cv_results['test_score'].mean(),4)}\") \n",
    "        # before : hyperparametre öncesi skoru ekrana yazdırılıyor\n",
    "        gs_best = GridSearchCV(classifier,params,cv=cv,n_jobs=-1,verbose=False).fit(X,y) \n",
    "        final_model = classifier.set_params(**gs_best.best_params_) \n",
    "        # after : hyperparametre sonrası skoru yazdırır \n",
    "        cv_results = cross_validate(final_model,X,y, cv=cv, scoring=scoring) \n",
    "        print(f\"{scoring} (After):{round(cv_results['test_score'].mean(),4)}\") \n",
    "        print(f\"{name} best params:{gs_best.best_params_}\",end=\"\\n\\n\") \n",
    "        best_models[name] = final_model \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce1a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier(best_models, X, y): \n",
    "    print(\"Voting Classifier....\") \n",
    "    # bana kullanacak olduğun modelleri söyle \n",
    "    # bu 3 modele göre en iyi modeli ortaya çıkar \n",
    "    voting_clf = VotingClassifier(estimators=[('KNN',best_models[\"KNN\"]),('RF',best_models[\"RF\"]),\n",
    "                                             ('LightGBM',best_models[\"LightGBM\"])],\n",
    "                                 voting='soft').fit(X,y) \n",
    "    \n",
    "    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=[\"accuracy\",\"f1\",\"roc_auc\"]) \n",
    "    print(f\"Accuracy: {cv_results['test_accuracy'].mean()}\") \n",
    "    print(f\"F1Score: {cv_results['test_f1'].mean()}\") \n",
    "    print(f\"ROC_AUC:{cv_results['test_roc_auc'].mean()}\") \n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0254100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "işlem başladı....\n",
      "Observations: 768\n",
      "Variables: 13\n",
      "cat_cols: 5\n",
      "num_cols: 8\n",
      "cat_but_car: 0\n",
      "num_but_cat: 4\n",
      "Observations: 768\n",
      "Variables: 17\n",
      "cat_cols: 9\n",
      "num_cols: 8\n",
      "cat_but_car: 0\n",
      "num_but_cat: 9\n",
      "Base Models.....\n",
      "roc_auc: 0.8409 (LR) \n",
      "roc_auc: 0.791 (KNN) \n",
      "roc_auc: 0.8355 (SVC) \n",
      "roc_auc: 0.6517 (CART) \n",
      "roc_auc: 0.8268 (RF) \n",
      "roc_auc: 0.8196 (Adaboost) \n",
      "roc_auc: 0.8248 (GBM) \n",
      "roc_auc: 0.8015 (XGBoost) \n",
      "roc_auc: 0.807 (LightGBM) \n",
      "Hyperparameter Optimization...\n",
      "#######  KNN ########\n",
      "roc_auc (Before):0.8211\n",
      "roc_auc (After):0.8211\n",
      "KNN best params:{'n_neighbors': 20}\n",
      "\n",
      "#######  CART ########\n",
      "roc_auc (Before):0.7943\n",
      "roc_auc (After):0.7943\n",
      "CART best params:{'max_depth': 6, 'min_samples_split': 23}\n",
      "\n",
      "#######  RF ########\n",
      "roc_auc (Before):0.8313\n",
      "roc_auc (After):0.8355\n",
      "RF best params:{'max_depth': 8, 'max_features': 7, 'min_samples_split': 15, 'n_estimators': 200}\n",
      "\n",
      "#######  XGBoost ########\n",
      "roc_auc (Before):0.8179\n",
      "roc_auc (After):0.8179\n",
      "XGBoost best params:{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
      "\n",
      "#######  LightGBM ########\n",
      "roc_auc (Before):0.8185\n",
      "roc_auc (After):0.8185\n",
      "LightGBM best params:{'learning_rate': 0.01, 'n_estimators': 300}\n",
      "\n",
      "Voting Classifier....\n",
      "Accuracy: 0.76953125\n",
      "F1Score: 0.6353485838779956\n",
      "ROC_AUC:0.8368611602810052\n"
     ]
    }
   ],
   "source": [
    "# işletim seviyesi şeklinde çalıştırıyor olmam gerekiyor  \n",
    "# Pipeline Main Function \n",
    "# terminalden bunu çalıştırmak istediğimde bu faydalı bir kullanımdır  \n",
    "# dışardan işlemi değiştirmek isterse main kısmından halledebilir \n",
    "# terminale gelip açmak için ; \"python diabetes_pipeline.py\" yazınız!!!!\n",
    "# #######################################################################\n",
    "def main():  \n",
    "    # veriyi çek\n",
    "    df = pd.read_csv(\"C:/Users/tolga/OneDrive/Masaüstü/ML_YAZ_KAMPI/Machine Learning/datasets/diabetes.csv\")\n",
    "    # veriyi önişleme\n",
    "    X,y = diabetes_data_prep(df)  \n",
    "    # genel modellere bak\n",
    "    base_models(X,y) \n",
    "    # hyperparametre optimizasyonu \n",
    "    best_models = hyperparameter_optimization(X,y)  \n",
    "    # en iyi modeli seç\n",
    "    voting_clf = voting_classifier(best_models, X,y)  \n",
    "    # model sürecini kaydet\n",
    "    joblib.dump(voting_clf,\"voting_clf.pkl\") \n",
    "    return voting_clf \n",
    "# double under score \n",
    "if __name__ == \"__main__\":  \n",
    "    print(\"işlem başladı....\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfd9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git github \n",
    "# makefile -> code otomasyon aracı  -> make train \n",
    "# veri tabanları \n",
    "# log \n",
    "# class \n",
    "# docker \n",
    "# requirement.txt "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
